{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descent Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Pre-requisites\n",
    "The symbol $\\mathbb{K}$ stands for the set of all real numbers $\\mathbb{R}$ or the set of all complex numbers $\\mathbb{C}$.\n",
    "\n",
    "### 0.1. Symmetric positive-definite matrix\n",
    "A squared symmetric matrix $A\\in\\mathbb{R}^{n\\times n}$ is said to be positive-definite if\n",
    "$$\\forall x\\in\\mathbb{R}^n\\setminus\\left\\{0\\right\\}\\quad x^TAx>0.$$\n",
    "### 0.2. Norm\n",
    "In a linear space $X$ over $\\mathbb{K}$ equipped with a real-valued functional $\\left\\|\\cdot\\right\\|\\colon X\\to \\mathbb{R}$ which satisfies the following properties:\n",
    "\n",
    "(i) $\\left\\|x\\right\\|\\ge 0$, for any $x\\in X$ and $\\left\\|x\\right\\|=0\\iff x=0$;\n",
    "\n",
    "(ii) $\\left\\|\\alpha x\\right\\|= \\left|\\alpha\\right|\\left\\|x\\right\\|$, for any $x\\in X$ and $\\alpha\\in\\mathbb{K}$;\n",
    "\n",
    "(iii) $\\left\\|x+y\\right\\|\\le \\left\\|x\\right\\|+\\left\\|y\\right\\|$, for any $x,y\\in X$;\n",
    "\n",
    "is called normed (linear) space and the functional is said to be a norm of $X$.\n",
    "### 0.3. Inner product\n",
    "In a linear space $X$ over $\\mathbb{K}$ consider the function $\\langle \\cdot,\\cdot\\rangle\\colon X\\times X\\to \\mathbb{K}$ that satisfies the following properties:\n",
    "\n",
    "(I) $\\langle x,x\\rangle\\ge 0$ for any $x\\in X$ and $\\langle x,x\\rangle = 0$ if, and only if $x=0$;\n",
    "\n",
    "(II) $\\langle \\alpha x,y\\rangle =\\alpha \\langle x,y\\rangle,$ for any $x,y\\in\\mathbb{X}$ and $\\alpha\\in\\mathbb{K}$;\n",
    "\n",
    "(III) $\\langle x,y\\rangle = \\overline{\\langle y,x\\rangle},$ for any $x,y\\in X$;\n",
    "\n",
    "(IV) $\\langle x+y,z\\rangle = \\langle x,z\\rangle + \\langle y,z\\rangle$, for any $x,y,z\\in X$.\n",
    "\n",
    "Under these configurations we call the function $\\langle \\cdot,\\cdot\\rangle$ an inner product.\n",
    "\n",
    "Furthermore it defines a norm on $X$ in the following settings:\n",
    "\n",
    "$$\\forall x\\in X\\quad \\left\\|x\\right\\|=\\sqrt{\\langle x,x\\rangle}.$$\n",
    "\n",
    "Example: take $x=(x_1,...,x_n),y=(y_1,...,y_n)\\in\\mathbb{R}^n$. Then\n",
    "$$\\langle x,y\\rangle=\\sum_{i=1}^nx_iy_i$$\n",
    "defines the natural inner product in $\\mathbb{R}^n$. if we see $x$ and $y$ as columns of dimension $n$, it yields\n",
    "$$\\langle x,y\\rangle = y^Tx.$$\n",
    "In particular,\n",
    "$$\\left\\|x\\right\\|_2=\\sqrt{x^Tx}$$\n",
    "defines a norm in $\\mathbb{R}^n$ which is frequently called Euclidean norm as it is just the formula for the distance in ordinary three-dimensional Euclidean space extended to dimension $n$.\n",
    "\n",
    "Example: Suppose that $A\\in\\mathbb{R}^{n\\times n}$ is a symmetric positive-definite matrix. Then the following bilinear form defines an inner product in $\\mathbb{R}^n$:\n",
    "$$\\langle x,y\\rangle_{A}=\\langle Ax,y\\rangle= y^TAx.$$\n",
    "In particular,\n",
    "$$\\left\\|x\\right\\|=\\sqrt{\\langle Ax,x\\rangle}=\\sqrt{x^TAx}$$\n",
    "is a norm in $\\mathbb{R}^n$.\n",
    "\n",
    "### 0.4. Matrix norm induced by the vector norm\n",
    "Let $A\\in\\mathbb{R}^{n\\times n}$ be a matrix and let $\\left|\\cdot\\right|\\colon \\mathbb{R}^n\\to \\mathbb{R}$ be a norm. Then $\\left\\|\\cdot\\right\\|\\colon \\mathbb{R}^{n\\times n}\\to\\mathbb{R}$ given by\n",
    "$$\\left\\|A\\right\\|=\\sup_{\\left|x\\right|=1}\\left|Ax\\right|$$\n",
    "defines a norm, which is also said to be a natural norm or matrix norm induced by the vector norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5 Important results\n",
    "1. Let $A\\in\\mathbb{R}^{n\\times n}$ be a symmetric positive-definite matrix and let $\\lambda_1\\le \\lambda_2\\le ...\\le \\lambda_n$ be the eigen values of $A$ and consider the euclidean norm in $\\mathbb{R}^n$,\n",
    "$$\\left\\|x\\right\\|_2=\\sqrt{x_1^2+...+x_n^2}.$$\n",
    "Under these configurations, we have\n",
    "$$\\left\\|A\\right\\|_2=\\lambda_n.$$\n",
    "\n",
    "2. The Cauchy-Schwarz inequality states that, for $x,y\\in\\mathbb{R}^n$, one has\n",
    "$$\\langle x,y\\rangle\\le \\left\\|x\\right\\|\\left\\|y\\right\\|$$\n",
    "and the equality is attained if $x$ and $y$ are colinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hypotesis\n",
    "We are given $n$ samples of $m$ features $(x_{11},x_{12},...,x_{1m}), (x_{21},x_{22},...,x_{2m}),..., (x_{n1},x_{n2},...,x_{nm})\\in\\mathbb{R}^m$ which assume values of $y_1,y_2,...,y_n\\in\\mathbb{R}$, respectively. Let us assume that the given dataset is \"rich enough\" (which will be discussed later), and suppose that the mapping $\\bold{x}\\mapsto y$ is \"almost\" linear. We would like to have the following equalities to be satisfied:\n",
    "$$\\begin{cases}\n",
    "\\theta_0 + \\theta_1x_{11}+\\theta_2x_{12}+...+\\theta_mx_{1m}=y_1 \\\\\n",
    "\\theta_0 + \\theta_1x_{21}+\\theta_2x_{22}+...+\\theta_mx_{2m}=y_2 \\\\\n",
    "\\qquad\\qquad\\qquad\\qquad \\vdots \\\\\n",
    "\\theta_0 + \\theta_1x_{n1}+\\theta_2x_{n2}+...+\\theta_mx_{nm}=y_n\n",
    "\\end{cases}$$\n",
    "which is represented matricially as\n",
    "$$\\begin{bmatrix}\n",
    "1&x_{11}&x_{12}&\\dots&x_{1m}\\\\\n",
    "1&x_{21}&x_{22}&\\dots&x_{2m}\\\\\n",
    "\\vdots &\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "1&x_{n1}&x_{n2}&\\dots&x_{nm}\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\theta_0\\\\\\theta_1\\\\ \\vdots \\\\ \\theta_m\n",
    "\\end{bmatrix}=\\begin{bmatrix}y_1\\\\y_2\\\\\\vdots\\\\ y_n\\end{bmatrix}.\n",
    "$$\n",
    "So we'd have to solve the system of linear equations $\\begin{bmatrix}\\bold{1}&\\bold{X}\\end{bmatrix}\\boldsymbol\\theta=\\bold{y}$, for unknown $\\boldsymbol\\theta$. If it has a solution $\\boldsymbol\\theta=(\\theta_0,\\theta_1,...,\\theta_m)$, then the graph function of $y\\colon \\mathbb{R}^m\\to \\mathbb{R}$, $y(x_1,...,x_m)=\\theta_0 + \\theta_1x_1+...+\\theta_mx_m$, which is $G_y\\colon \\mathbb{R}^{m}\\mapsto\\mathbb{R}^{m+1}$, $\\bold{x}\\mapsto (\\bold{x}, y(\\bold{x}))$ passes through all the given points. This is a interpolation problem, which is not of our interest.\n",
    "\n",
    "For our purpose, we assume that $m\\ll n$ and that the training matrix with intercept has full column rank. In other words, we must not have perfect multicolinearity. By all this we mean that the dataset is \"rich enough\". In this conformity there would not be a solution for the linear equation, but rather a good approximation \"solution\". In fact, for any given $\\boldsymbol\\theta$ there is some $\\boldsymbol\\varepsilon = (\\varepsilon_1,...,\\varepsilon_n)$, such that\n",
    "$$\\begin{bmatrix}\\bold{1}&\\bold{X}\\end{bmatrix}\\boldsymbol\\theta+\\boldsymbol\\varepsilon=\\bold{y}.$$\n",
    "So then the aim is to find $\\theta$ such that $\\varepsilon$ in length is as small as possible. In other words, we tend to find the minimizer (if it exists) of the functional\n",
    "$$J(\\boldsymbol\\theta)=\\left\\|\\bold{A}\\boldsymbol\\theta-\\bold{y}\\right\\|^2_2,$$\n",
    "where $\\bold{A}=\\begin{bmatrix}\\bold{1}&\\bold{X}\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Equivalent problem\n",
    "Suppose that $A\\in \\mathbb{R}^{n\\times p}$ and $b\\in\\mathbb{R}^n$ with $\\text{r}(A)=p$. The minimization problem of $$x\\mapsto J(x)=\\frac{1}{2}\\left\\|Ax-b\\right\\|_2^2$$ is equivalent to solving the following linear (normal) equation: $$A^TAx=A^Tb.$$ In other words, the unique solution of the normal equation is also the unique minimizer of $J$.\n",
    "\n",
    "Sketch of proof: The stacionary point of $J$ is $x$, one that yields $\\nabla J(x)=0$, that is $A^T(Ax-b)=0$, which is equivalent to $A^TAx=A^Tb$. This is indeed the unique minimizer, since the Hessian matrix of $J$ is $H_J=A^TA$ which is positive-definite, whence also invertible.\n",
    "\n",
    "So, considering $A_{\\text{new}}={A_{\\text{old}}}^TA_{\\text{old}}$ and $b_{\\text{new}}={A_{\\text{old}}}^Tb_{\\text{old}}$, it all reduces to solving the following linear equation:\n",
    "$$Ax=b,$$\n",
    "where $A\\in\\mathbb{R}^{p\\times p}$ is (symmetric) positive-definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descent Method with optimal step\n",
    "Suppose that $u$ satisfies the linear equation $Ax=b$. Since $A$ is positive-definite by assumption, $u$ is the unique vector that annihilates the quadratic functional $E\\colon \\mathbb{R}^p\\to \\mathbb{R}$ given by the canonical inner product\n",
    "$$\n",
    "E(x)=\\langle A(x-u),x-u\\rangle \\ge 0.\n",
    "$$\n",
    "Consider the following algorithm:\n",
    "$$\n",
    "\\begin{cases}\n",
    "u^0\\quad\\text{fixed}\\\\\n",
    "u^{k+1}=u^k-\\rho^kd^k& k=0,1,2,...\n",
    "\\end{cases}\n",
    "$$\n",
    "where we choose the direction of the descent $d^k$ on each iteration.\n",
    "\n",
    "Idea: Knowing $u^k$ and choosing $d^k$, how to attain $\\rho^k$?\n",
    "\n",
    "Answer: $E(u^k-\\rho^kd^k)=\\min_{\\rho\\in\\mathbb{R}}E(u^k-\\rho d^k)$.\n",
    "\n",
    "Computations:\n",
    "\n",
    "$E(u^k-\\rho d^k)=\\langle A(u^k-\\rho d^k-u),u^k-\\rho d^k-u\\rangle = \\langle A(u^k-u),u^k-u \\rangle - \\rho\\langle Ad^k,u^k-u\\rangle - \\rho\\langle A(u^k-u),d^k \\rangle + \\rho^2\\langle A d^k,d^k\\rangle = E(u^k)-2\\rho\\langle A(u^k-u),d^k\\rangle+\\rho^2 \\langle A d^k,d^k\\rangle.$\n",
    "\n",
    "By considering the residual term $r^k = Au^k-b$, we arrive at the following equality:\n",
    "$$E(u^k-\\rho d^k)=E(u^k)-2\\rho\\langle r^k,d^k\\rangle+\\rho^2 \\langle A d^k,d^k\\rangle.$$\n",
    "We then recognize the quadratic polynomial $\\alpha+\\rho\\beta+\\rho^2\\gamma$ with the leading factor $\\gamma = \\langle A d^k,d^k\\rangle>0$, and so the minimum is attained at \n",
    "$$\\rho=-\\frac{\\beta}{2\\gamma}=\\frac{\\langle r^k,d^k\\rangle}{\\langle A d^k,d^k\\rangle}.$$\n",
    "\n",
    "Notice that indeed we have\n",
    "$$E(u^{k+1})=E(u^k-\\rho^k d^k)=E(u^k)-\\frac{\\langle r^k,d^k\\rangle^2}{\\langle A d^k,d^k\\rangle}\\le E(u^k).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Convergence\n",
    "Our goal is to show then, that $u^k\\to u$ as $k\\to\\infty$. It is sufficient to check if $$\\lim_{k\\to\\infty}E(u^k)=0.$$\n",
    "\n",
    "Notice that\n",
    "$$r^k=Au^k-b=A(u^k-u)\\implies u^k-u=A^{-1}r^k$$\n",
    "from which we have\n",
    "$$E(u^k)=\\langle A(u^k-u),u^k-u \\rangle = \\langle r^k,A^{-1}r^k\\rangle .$$\n",
    "But\n",
    "$$E(u^{k+1})=E(u^k)-\\frac{\\langle r^k,d^k\\rangle^2}{\\langle A d^k,d^k\\rangle}=E(u^k)\\left[1-\\frac{\\langle r^k,d^k\\rangle^2}{E(u^k)\\langle A d^k,d^k\\rangle}\\right].$$\n",
    "Our purpose is to limit above the expression in the right parentesis by a number smaller than $1$. In this conformity, recall that the Cauchy-Schwarz inequality yields:\n",
    "$$\\langle Ad^k,d^k\\rangle \\le\\lambda_n \\left\\|d^k\\right\\|_2^2\\quad\\text{and}\\quad \\langle r^k,A^{-1}r^k\\rangle\\le \\frac{1}{\\lambda_1}\\left\\|r^k\\right\\|_2^2,$$\n",
    "where $\\lambda_1\\le \\lambda_2\\le ...\\le \\lambda_n$ are the eigen values of $A$. So we therefore have\n",
    "$$\\langle Ad^k,d^k\\rangle\\langle r^k,A^{-1}r^k\\rangle \\le \\underbrace{\\frac{\\lambda_n}{\\lambda_1}}_{\\kappa_2(A)}\\left\\|d^k\\right\\|_2^2\\left\\|r^k\\right\\|_2^2,$$\n",
    "where $\\kappa_2(A):=\\left\\|A\\right\\|_2\\left\\|A^{-1}\\right\\|_2$ is the condition number of $A$. The above inequality is equivalent to\n",
    "$$\n",
    "-\\frac{1}{\\langle Ad^k,d^k\\rangle\\langle r^k,A^{-1}r^k\\rangle}\\le -\\frac{1}{\\kappa_2(A)\\left\\|d^k\\right\\|_2^2\\left\\|r^k\\right\\|_2^2},\n",
    "$$\n",
    "and so\n",
    "$$\n",
    "E(u^{k+1})\\le E(u^k)\\left[1-\\frac{\\langle r^k,d^k\\rangle^2}{\\kappa_2(A)\\left\\|d^k\\right\\|_2^2\\left\\|r^k\\right\\|_2^2}\\right]=E(u^k)\\left[1-\\frac{1}{\\kappa_2(A)}\\left<\\frac{r^k}{\\left\\|r^k\\right\\|_2},\\frac{d^k}{\\left\\|d^k\\right\\|_2}\\right>^2\\right].\n",
    "$$\n",
    "Let us assume that $$0<\\mu\\le \\left<\\frac{r^k}{\\left\\|r^k\\right\\|_2},\\frac{d^k}{\\left\\|d^k\\right\\|_2}\\right>^2.$$\n",
    "Notice that\n",
    "$$I=AA^{-1}\\implies 1=\\left\\|I\\right\\|\\le \\left\\|A\\right\\|\\left\\|A^{-1}\\right\\|=\\kappa(A)\\implies \\frac{1}{\\kappa(A)}\\le 1.$$\n",
    "So, the inequality\n",
    "$$0<\\frac{\\mu}{\\kappa_2(A)}\\le \\frac{1}{\\kappa_2(A)}\\left<\\frac{r^k}{\\left\\|r^k\\right\\|_2},\\frac{d^k}{\\left\\|d^k\\right\\|_2}\\right>^2$$\n",
    "leads to\n",
    "$$1>1-\\frac{\\mu}{\\kappa_2(A)}\\ge 1-\\frac{1}{\\kappa_2(A)}\\left<\\frac{r^k}{\\left\\|r^k\\right\\|_2},\\frac{d^k}{\\left\\|d^k\\right\\|_2}\\right>^2.$$\n",
    "It yields the following relation\n",
    "$$E(u^{k+1})\\le E(u^k)\\left[1-\\frac{\\mu}{\\kappa_2(A)}\\right].$$\n",
    "Whence\n",
    "$$E(u^{k+1})\\le E(u^0)\\left[1-\\frac{\\mu}{\\kappa_2(A)}\\right]^{k+1}\\to 0$$\n",
    "as $k\\to\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. The Algorithm\n",
    "We proved the following.\n",
    "Given $A\\in\\mathbb{R}^p$ symmetric positive-definite matrix, $b\\in\\mathbb{R}^p$ and choose $u_0\\in\\mathbb{R}^p$. Let $$u^{k+1}=u^k-\\rho^kd^k,$$ for chosen $d^k\\in\\mathbb{R}^p$, $$r^k=Au^k-b$$ and $$\\rho^k=\\frac{\\langle r^k,d^k\\rangle}{\\langle Ad^k,d^k\\rangle},$$ for any $k\\in\\mathbb{N}$. Let $E\\colon \\mathbb{R}^p\\to \\mathbb{R}$ be the quadratic functional\n",
    "$$E(x)=\\langle A(x-u),x-u\\rangle,\\quad x\\in\\mathbb{R}^p$$\n",
    "and $\\mu$ be a real number such that\n",
    "$$0<\\mu\\le \\left<\\frac{r^k}{\\left\\|r^k\\right\\|_2},\\frac{d^k}{\\left\\|d^k\\right\\|_2}\\right>^2,$$\n",
    "for any $k\\in\\mathbb{N}$. Then\n",
    "$$\\lim_{k\\to\\infty}u^k=u$$\n",
    "and $u$ is the unique solution to the system of linear equations $Ax=b$.\n",
    "\n",
    "We will make the following choices: Choose $u^0=\\bold{0}$, and the direction of descent $d^k$ to be chosen cyclically $e_1,e_2,...,e_p,e_1,e_2,...,e_p,...$, where\n",
    "$e_i=(0,...,\\underset{i\\text{-th entry}}{1},...,0)$. Note that we would like to have $\\mu>0$ such that\n",
    "$$\n",
    "\\frac{\\left|r^k_i\\right|^2}{\\left\\|r^k\\right\\|^2}>\\mu,\n",
    "$$\n",
    "where $r^k_i$ is the $i$-th entry of $r^k$. If, for some reason the above inequality doesn't happen, we can skip to the next descent direction. In fact, at least one of the direction will satisfy the above inequality. To prove it, suppose the contrary, i.e., for any $i=1,...,p$ one has\n",
    "$$\\frac{\\left|r^k_i\\right|^2}{\\left\\|r^k\\right\\|^2}\\le\\mu.$$\n",
    "We therefore sum in $i$ and achieve $1\\le p\\mu$. But, since we can choose $\\mu$ to be less than $p$, it yields a contradiction. So the algorithm works fine and we don't need to worry about the choice of $\\mu$.\n",
    "\n",
    "Recall that\n",
    "$$r^{k+1}=Au^{k+1}-b=A(u^k-\\rho^kd^k)-b=Au^k-b-\\rho^k Ad^k=r^k-\\rho^k Ad^k.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 3.3. Time to Code!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
